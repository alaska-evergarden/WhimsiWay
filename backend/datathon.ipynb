{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start_Lat  Start_Lng\n",
      "0  39.865147 -84.058723\n",
      "1  39.928059 -82.831184\n",
      "2  39.063148 -84.032608\n",
      "3  39.747753 -84.205582\n",
      "4  39.627781 -84.188354\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "file_path = \"US_Accidents_March23.csv\"\n",
    "data = pd.read_csv(file_path, nrows=10000, usecols=['Start_Lat', 'Start_Lng'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_geo(data,\n",
    "                     lat='Start_Lat',\n",
    "                     lon='Start_Lng',\n",
    "                     scope='usa',  # Focus the map on the USA\n",
    "                     title='Traffic Accident Hotspots in the US',\n",
    "                     projection='albers usa',  # Use the Albers projection for the USA\n",
    "                     hover_name='Start_Lat',  # Show latitude on hover (you can customize this)\n",
    "                     color_discrete_sequence=['red'],  # Use red dots to represent accidents\n",
    "                     )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_csv(\"US_Accidents_March23.csv\", nrows=100000)\n",
    "\n",
    "# Assuming your CSV has 'latitude' and 'longitude' columns\n",
    "latitude = 'Start_Lat'\n",
    "longitude = 'Start_Lng'\n",
    "\n",
    "# Step 2: Preprocess the data (if necessary, depending on your CSV structure)\n",
    "# This step is skipped here but involves ensuring data types are correct, handling missing values, etc.\n",
    "\n",
    "# Step 3: Clustering\n",
    "# Convert location data to a numpy array for DBSCAN\n",
    "coords = df[[latitude, longitude]].to_numpy()\n",
    "\n",
    "# DBSCAN clustering\n",
    "db = DBSCAN(eps=0.01, min_samples=10, algorithm='ball_tree', metric='haversine').fit_predict(np.radians(coords))\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "df['cluster'] = db\n",
    "\n",
    "# Filter out noise (-1 labels)\n",
    "df_clustered = df[df['cluster'] != -1]\n",
    "\n",
    "# Step 4: Mapping with Folium\n",
    "# Create a map centered around an average location\n",
    "map_us = folium.Map(location=[df[latitude].mean(), df[longitude].mean()], zoom_start=5)\n",
    "\n",
    "# Generate clusters for the heatmap (average location of points in each cluster)\n",
    "clusters = df_clustered.groupby('cluster')[[latitude, longitude]].mean().values\n",
    "\n",
    "# Add a heat map layer for accident hotspots\n",
    "HeatMap(clusters).add_to(map_us)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map_us.save('us_traffic_accident_hotspots.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Step 1: Load the accident data\n",
    "df = pd.read_csv('path_to_your_csv_file.csv', nrows=100000)\n",
    "# Ensure correct data types for latitude and longitude\n",
    "df['latitude'] = df['latitude'].astype(float)\n",
    "df['longitude'] = df['longitude'].astype(float)\n",
    "\n",
    "# Step 2: Convert your DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "\n",
    "# Step 3: Load a shapefile of the US states (ensure you have one that includes Texas)\n",
    "# You can find shapefiles of US states online, e.g., from the US Census Bureau or Natural Earth Data\n",
    "states = gpd.read_file('path_to_shapefile_of_US_states.shp')\n",
    "\n",
    "# Filter the shapefile to include only Texas\n",
    "texas = states[states['NAME'] == 'Texas']\n",
    "\n",
    "# Step 4: Filter your data points to include only those within Texas\n",
    "# This creates a boolean series that's True for points within the Texas geometry\n",
    "points_in_texas = gdf.within(texas.iloc[0].geometry)\n",
    "\n",
    "# Filter the GeoDataFrame to keep only points in Texas\n",
    "gdf_texas = gdf[points_in_texas]\n",
    "\n",
    "# Now, gdf_texas contains only the points that are within Texas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load the accident data\n",
    "df = pd.read_csv(\"US_Accidents_March23.csv\", usecols=['Start_Lat', 'Start_Lng'], nrows=100000)\n",
    "\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "gdf_accidents = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Start_Lng, df.Start_Lat))\n",
    "\n",
    "# Load the Texas shapefile\n",
    "gdf_texas = gpd.read_file(\"tl_2016_48_cousub.shp\")\n",
    "\n",
    "# Ensure both GeoDataFrames use the same CRS\n",
    "gdf_accidents.crs = gdf_texas.crs\n",
    "\n",
    "# Filter accidents to include only those within Texas\n",
    "texas_accidents = gpd.sjoin(gdf_accidents, gdf_texas, how=\"inner\", op='intersects')\n",
    "\n",
    "# texas_accidents now contains only the accidents that occurred within Texas\n",
    "print(texas_accidents.head())\n",
    "\n",
    "# Optional: Save the filtered data to a new CSV file\n",
    "texas_accidents.to_csv(\"Texas_Accidents.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
